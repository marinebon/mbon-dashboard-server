# Airflow sections based on provided example docker-compose.yml included in
# airflow's docs here:
# https://airflow.apache.org/docs/apache-airflow/stable/docker-compose.yaml
---
version: '3.3'

# ============================================================================
# === config shared between all airflow services =============================
# ============================================================================
# This config supports use of environment variables or an .env file.
# The following variables are supported:
#
# AIRFLOW_IMAGE_NAME         - Docker image name used to run Airflow.
#                              Default: apache/airflow:master-python3.8
# AIRFLOW_UID                - User ID in Airflow containers
#                              Default: 50000
# AIRFLOW_GID                - Group ID in Airflow containers
#                              Default: 50000
# _AIRFLOW_WWW_USER_USERNAME - Username for the administrator account.
#                              Default: airflow
# _AIRFLOW_WWW_USER_PASSWORD - Password for the administrator account.
#                              Default: airflow
x-airflow-common:
  &airflow-common
  image: ${AIRFLOW_IMAGE_NAME:-apache/airflow:2.0.1}
  environment:
    &airflow-common-env
    AIRFLOW__CORE__EXECUTOR: CeleryExecutor
    AIRFLOW__CORE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@postgres/airflow
    AIRFLOW__CELERY__RESULT_BACKEND: db+postgresql://airflow:airflow@postgres/airflow
    AIRFLOW__CELERY__BROKER_URL: redis://:@redis:6379/0
    AIRFLOW__CORE__FERNET_KEY: ''
    AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION: 'false'
    AIRFLOW__CORE__LOAD_EXAMPLES: 'false'
    UPLOADER_HOSTNAME: http://35.209.104.85:5000
#    env_file:
#        - .env
  volumes:
    - ./airflow/dags:/opt/airflow/dags
    - ./airflow/logs:/opt/airflow/logs
    - ./airflow/plugins:/opt/airflow/plugins
#     - /srv/imars-objects:/srv/imars-objects:ro,slave
#     - ./airflow/requirements.txt:/requirements.txt
  user: "${AIRFLOW_UID:-50000}:${AIRFLOW_GID:-50000}"
  depends_on:
    redis:
      condition: service_healthy
    postgres:
      condition: service_healthy
# ============================================================================

services:
  nginx:
    container_name: nginx
    build: ./nginx
    restart: unless-stopped
    ports:
      - 80:80
    volumes:
      - ./static_files:/usr/share/nginx/html:ro
  # docker run -d -p 8080:8080 --name erddap axiom/docker-erddap
  erddap:
    user: root:4504
    container_name: erddap
    build: ./erddap
    volumes:
     - ./erddap/erddap_data:/erddapData
     - ./erddap/content:/usr/local/tomcat/content/erddap
     # === ERDDAP dataset mounts==============================================
     # NOTE: paths must match "fileDir" paths in erddap/content/datsets.xml
     - /srv/imars-objects:/srv/erddap-datasets:ro,slave
     # =======================================================================
    restart: unless-stopped
    ports:
      - 8080:8080
 # sudo docker exec -it erddap bash -c "cd /usr/local/tomcat/webapps/erddap/WEB-INF && bash GenerateDatasetsXml.sh -verbose"

  # ==========================================================================
  # === grafana dashboard services
  # ==========================================================================
  grafana:
      container_name: grafana
      image: grafana/grafana:6.7.3
      ports:
          - 3000:3000
      environment:
          - "GF_INSTALL_PLUGINS=alexandra-trackmap-panel,pierosavi-imageit-panel,https://github.com/USF-IMARS/grafana-erddap/releases/download/1.0.0/grafana-erddap.zip;grafana-erddap"
          - GF_PATHS_PROVISIONING=/grafana_provisioning
          - GF_AUTH_ANONYMOUS_ENABLED=true
          - GF_SECURITY_ADMIN_USER=imars_grafana_user
          - GF_SECURITY_ADMIN_PASSWORD=${GF_SECURITY_ADMIN_PASSWORD}
          - INFLUXDB_HOSTNAME=http://localhost:8086
          - INFLUXDB_GRAPHITE_HOSTNAME=http://localhost:2003
      volumes:
          - ./grafana/provisioning:/grafana_provisioning
          - ./grafana/grafana-storage:/var/lib/grafana
  influxdb:
        container_name: influxdb
        image: influxdb:1.8
        ports:
            - 8086:8086  # HTTP API
            - 2003:2003  # graphite API
        volumes:
            # init the db by putting .sh or .iql files in /docker-entrypoint-initdb.d
            # this should inlcude adding a read-only user for grafana
            - ./influxdb/initdb:/docker-entrypoint-initdb.d
            # docker data volume:
            - ./influxdb/data_volume:/var/lib/influxdb
        environment:
            - INFLUXDB_DB=fwc_coral_disease
            - INFLUXDB_GRAPHITE_ENABLED=true
            - INFLUXDB_HTTP_AUTH_ENABLED=false  # TODO: make this true & + users. See
            # - INFLUXDB_USER=influx_user         #       See https://github.com/influxdata/influxdata-docker/issues/232
            # - INFLUXDB_ADMIN_USER=influx_admin  #       and https://github.com/influxdata/influxdata-docker/issues/224
            # - INFLUXDB_READ_USER=grafana
            # - INFLUXDB_WRITE_USER=telegraf
  # ==========================================================================
  mbon_data_uploader:
      container_name: mbon_data_uploader
      build: ./mbon_data_uploader
      ports:
          - 5000:5000
      environment:
          - FLASK_APP=mbon_data_uploader  # TODO: this can be deleted?
          - INFLUXDB_HOSTNAME=localhost:8086

  # ==========================================================================
  # === airflow job orchestration services
  # ==========================================================================
  postgres:
    image: postgres:13
    environment:
      POSTGRES_USER: airflow
      POSTGRES_PASSWORD: airflow  # ${POSTGRES_PASSWORD}
      POSTGRES_DB: airflow
    volumes:
      - postgres-db-volume:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD", "pg_isready", "-U", "airflow"]
      interval: 5s
      retries: 5
    restart: always

  redis:
    image: redis:latest
    ports:
      - 6379:6379
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 5s
      timeout: 30s
      retries: 50
    restart: always

  airflow-webserver:
    <<: *airflow-common
    command: webserver
    ports:
      - 8888:8080
    healthcheck:
      test: ["CMD", "curl", "--fail", "http://localhost:8080/health"]
      interval: 10s
      timeout: 10s
      retries: 5
    restart: always
    # container_name: airflow_webserver
    # mem_limit: 2048m
  airflow-scheduler:
    <<: *airflow-common
    command: scheduler
    restart: always

  airflow-worker:
    <<: *airflow-common
    command: celery worker
    restart: always

  airflow-init:
    <<: *airflow-common
    command: version
    environment:
      <<: *airflow-common-env
      _AIRFLOW_DB_UPGRADE: 'true'
      _AIRFLOW_WWW_USER_CREATE: 'true'
      _AIRFLOW_WWW_USER_USERNAME: ${_AIRFLOW_WWW_USER_USERNAME:-airflow}
      _AIRFLOW_WWW_USER_PASSWORD: ${_AIRFLOW_WWW_USER_PASSWORD:-airflow}

  flower:
    <<: *airflow-common
    command: celery flower
    ports:
      - 5555:5555
    healthcheck:
      test: ["CMD", "curl", "--fail", "http://localhost:5555/"]
      interval: 10s
      timeout: 10s
      retries: 5
    restart: always
  # ==========================================================================

volumes:
  postgres-db-volume:
