# Airflow sections based on provided example docker-compose.yml included in
# airflow's docs here:
# https://airflow.apache.org/docs/apache-airflow/stable/docker-compose.yaml
---

# ============================================================================
# === config shared between containers =======================================
# ============================================================================
x-global-common:
  &global-common
  environment:
    &global-common-env
    INFLUXDB_HOSTNAME: http://${SERVER_IP}:8086
    INFLUXDB_TOKEN: ${INFLUXDB_TOKEN}
# ============================================================================
# ============================================================================
# === config shared between all airflow services =============================
# ============================================================================
x-airflow-common:
  &airflow-common
  <<: *global-common
  environment:
    &airflow-common-env
    <<: *global-common-env
    AIRFLOW__CORE__EXECUTOR: CeleryExecutor
    AIRFLOW__CORE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@postgres/airflow  # TODO: rm this bc it is deprecated
    AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@postgres/airflow
    AIRFLOW__CELERY__RESULT_BACKEND: db+postgresql://airflow:airflow@postgres/airflow
    AIRFLOW__CELERY__BROKER_URL: redis://:@redis:6379/0
    AIRFLOW__CORE__FERNET_KEY: ''
    AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION: 'false'
    AIRFLOW__CORE__LOAD_EXAMPLES: 'false'
    AIRFLOW__CORE__PARALLELISM: '1'
    UPLOADER_HOSTNAME: http://${SERVER_IP}:5000
    SQLALCHEMY_WARN_20: 0  # set to 1 verbose logging about sqlAlchemy deprecations
    AIRFLOW__LOGGING__LOGGING_LEVEL: INFO  # DEBUG
    AIRFLOW_HOME: /opt/airflow/
  volumes:
    - ./airflow/dags:/opt/airflow/dags
    - airflow-logs-volume:/opt/airflow/logs
    - ./airflow/plugins:/opt/airflow/plugins
#     - /srv/imars-objects:/srv/imars-objects:ro,slave
#     - ./airflow/requirements.txt:/requirements.txt
  user: "${AIRFLOW_UID:-50000}:${AIRFLOW_GID:-0}"  # user & group ID in airflow containers
  depends_on:
    redis:
      condition: service_healthy
    postgres:
      condition: service_healthy
  build:
    context: ./airflow
    args:
      INFLUXDB_HOSTNAME: http://${SERVER_IP}:8086
      INFLUXDB_TOKEN: ${INFLUXDB_TOKEN}

# ============================================================================

services:
  nginx:
    container_name: nginx
    build: ./nginx
    restart: unless-stopped
    ports:
      - 80:80
      - 443:443
    volumes:
      - ./static_files:/usr/share/nginx/html:ro
      - ./certs:/etc/nginx/certs
    env_file:
      - .env
      
  # ==========================================================================
  # === grafana dashboard services
  # ==========================================================================
  grafana:
      <<: *global-common
      container_name: grafana
      image: grafana/grafana:10.4.4
      ports:
          - 3000:3000
      environment:
          <<: *global-common-env
          GF_INSTALL_PLUGINS: "alexandra-trackmap-panel,pierosavi-imageit-panel,fatcloud-windrose-panel,https://github.com/USF-IMARS/grafana-erddap/releases/download/1.0.0/grafana-erddap.zip;grafana-erddap"
          GF_PLUGINS_ALLOW_LOADING_UNSIGNED_PLUGINS: "erddap-panel"
          GF_PATHS_PROVISIONING: /grafana_provisioning
          GF_AUTH_ANONYMOUS_ENABLED: true
          GF_SECURITY_ADMIN_USER: imars_grafana_user
          GF_SECURITY_ADMIN_PASSWORD: ${GF_SECURITY_ADMIN_PASSWORD}
          INFLUXDB_GRAPHITE_HOSTNAME: http://${SERVER_IP}:2003
          GF_DASHBOARDS_DEFAULT_HOME_DASHBOARD_PATH: /grafana_provisioning/dashboards/home_dashboard.json
          #GF_SERVER_ROOT_URL: http://fknms.mbon-dashboards.marine.usf.edu/
          #GF_SERVER_SERVER_FROM_SUB_PATH: true
          
      volumes:
          - ./grafana/provisioning:/grafana_provisioning
          - grafana-storage:/var/lib/grafana
      env_file:
          - .env
  influxdb:
        container_name: influxdb
        image: influxdb:2.7.6
        ports:
            - 8086:8086  # HTTP API
            - 2003:2003  # graphite API
        volumes:
            # init the db by putting .sh or .iql files in /docker-entrypoint-initdb.d
            # this should inlcude adding a read-only user for grafana
            - ./influxdb/initdb:/docker-entrypoint-initdb.d
            # docker data volume:
            - influx-data-volume:/var/lib/influxdb
        restart: always
        environment:
            - INFLUXDB_DB=fwc_coral_disease
            - INFLUXDB_GRAPHITE_ENABLED=true
            - INFLUXDB_HTTP_AUTH_ENABLED=false  # TODO: make this true & + users. See
            # === logging settings
            - INFLUXDB_LOGGING_LEVEL=warn
            - INFLUXDB_META_LOGGING_ENABLED=false
            # - INFLUXDB_DATA_TRACE_LOGGING_ENABLED=false
            - INFLUXDB_DATA_QUERY_LOG_ENABLED=false
            - INFLUXDB_HTTP_LOG_ENABLED=false
            - INFLUXDB_CONTINUOUS_QUERIES_LOG_ENABLED=false
            # === user setup
            - DOCKER_INFLUXDB_INIT_MODE=setup
            - DOCKER_INFLUXDB_INIT_USERNAME=imars_influx_user
            - DOCKER_INFLUXDB_INIT_PASSWORD=${INFLUX_PASSWORD}
            - DOCKER_INFLUXDB_INIT_ORG=imars
            - DOCKER_INFLUXDB_INIT_BUCKET=imars_bucket
            # - DOCKER_INFLUXDB_INIT_RETENTION=1w
            - DOCKER_INFLUXDB_INIT_ADMIN_TOKEN=${INFLUX_ADMIN_TOKEN} 
            # - INFLUXDB_USER=influx_user         #       See https://github.com/influxdata/influxdata-docker/issues/232
            # - INFLUXDB_ADMIN_USER=influx_admin  #       and https://github.com/influxdata/influxdata-docker/issues/224
            # - INFLUXDB_READ_USER=grafana
            # - INFLUXDB_WRITE_USER=telegraf
        env_file:
            - .env
  # ==========================================================================
# DEPRECATED
#  mbon_data_uploader:
#      container_name: mbon_data_uploader
#      build: ./mbon_data_uploader
#      ports:
#          - 5000:5000
#      environment:
#          - FLASK_APP=mbon_data_uploader  # TODO: this can be deleted?
#          - INFLUXDB_HOSTNAME=${SERVER_IP}:8086

  # ==========================================================================
  # === airflow job orchestration services
  # ==========================================================================
  postgres:
    image: postgres:13
    environment:
      POSTGRES_USER: airflow
      POSTGRES_PASSWORD: airflow  # ${POSTGRES_PASSWORD}
      POSTGRES_DB: airflow
    volumes:
      - postgres-db-volume:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD", "pg_isready", "-U", "airflow"]
      interval: 5s
      retries: 5
    restart: always
    env_file:
      - .env
      
  redis:
    image: redis:latest
    expose:
      - 6379:6379
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 5s
      timeout: 30s
      retries: 50
    restart: always
    env_file:
      - .env
      
  airflow-webserver:
    <<: *airflow-common
    command: webserver
    ports:
      - 8888:8080
    healthcheck:
      test: ["CMD", "curl", "--fail", "http://${SERVER_IP}:8080/health"]
      interval: 10s
      timeout: 10s
      retries: 5
    restart: always
    # container_name: airflow_webserver
    # mem_limit: 2048m
    env_file:
      - .env
      
  airflow-scheduler:
    <<: *airflow-common
    command: scheduler
    restart: always
    env_file:
      - .env
      
  airflow-worker:
    <<: *airflow-common
    command: celery worker
    restart: always
    env_file:
      - .env
      
  airflow-init:
    <<: *airflow-common
    command: version
    environment:
      <<: *airflow-common-env
      _AIRFLOW_DB_UPGRADE: 'true'
      _AIRFLOW_WWW_USER_CREATE: 'true'
      _AIRFLOW_WWW_USER_USERNAME: ${_AIRFLOW_WWW_USER_USERNAME:-airflow}  # un for admin login
      _AIRFLOW_WWW_USER_PASSWORD: ${_AIRFLOW_WWW_USER_PASSWORD:-airflow}  # pw for admin login
    env_file:
      - .env
      
  flower:
    <<: *airflow-common
    command: celery flower
    ports:
      - 5555:5555
    healthcheck:
      test: ["CMD", "curl", "--fail", "http://${SERVER_IP}:5555/"]
      interval: 10s
      timeout: 10s
      retries: 5
    restart: always
    env_file:
      - .env
  # ==========================================================================

volumes:
  postgres-db-volume:
  influx-data-volume:
  grafana-storage:
  airflow-logs-volume:
